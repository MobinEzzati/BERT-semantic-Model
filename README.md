# BERT-semantic-Model
The foundational model that we will be training on is a pre-trained model that was trained by using Bidirectional Encoder Representations and Transformers (BERT).
